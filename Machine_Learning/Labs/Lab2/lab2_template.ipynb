{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive (optional)"
      ],
      "metadata": {
        "id": "1poT-tpUWgo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UxG3aEmhWiV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 2 : Decision Tree and Random Forest**\n",
        "In *lab 2*, you need to finish :\n",
        "\n",
        "1. Basic Part :\n",
        "  Implement a Decision Tree model and predict whether patients in the validation set survived.\n",
        "\n",
        "  > * Section 1: Function Implementation and Testing\n",
        "  > * Section 2: Building the Decision Tree Model\n",
        "\n",
        "\n",
        "2. Advanced Part : Build a **Random Forest** model to make predictions\n"
      ],
      "metadata": {
        "id": "NHYT0wwCWjlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "❗ **Important** ❗\n",
        "Please follow the template. Follow the instructions.\n",
        "**Do not** change the code outside this code bracket if you see one.\n",
        "```\n",
        "### START CODE HERE ###\n",
        "...\n",
        "### END CODE HERE ###\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "HtkN1RNQKznC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be using **pandas** frequently in this template, so we've provided a link to help you get familiar with its usage: https://pandas.pydata.org/docs/user_guide/10min.html\n"
      ],
      "metadata": {
        "id": "ViMa9pPp0L8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages\n",
        "\n",
        "> Note : You **cannot** import any other packages in both basic and advanced part\n"
      ],
      "metadata": {
        "id": "tBzqwVcaWqll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "from numpy import sqrt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "eb6ccSWDWrTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Part** (30%)\n",
        "\n",
        "## Section 1: Function Implementation and Testing\n",
        "You will implement five functions that are necessary for building a decision tree model. After implementing each function, you must run it with the given input variables to verify its correctness. Save the results of each function to a CSV file for submission.\n",
        "> * Step 1: Calculate the Entropy\n",
        "> * Step 2: Calculate the Information Gain\n",
        "> * Step 3: Find the Best Split\n",
        "> * Step 4: Split the data into two branches\n",
        "> * Step 5: Build the decision tree\n",
        "> * Step 6: Save answers\n",
        "\n",
        "\n",
        "## Section 2: Build a Decision Tree Model and make Predictions\n",
        "After implementing the functions, you will use them to build a decision tree model and make predictions. Follow the steps below to train your model and evaluate its performance.\n",
        "> * Step 1: Split the data into training set and validation set\n",
        "> * Step 2: Train a decision tree model with the training set\n",
        "> * Step 3: Predict the cases in the validation set by using the model trained in Step 2\n",
        "> * Step 4: Calculate the f1-score of your predictions in Step 3\n",
        "> * Step 5: Save answer"
      ],
      "metadata": {
        "id": "fHwMS_7dWtwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the input data\n",
        "Let's load the input file **lab2_basic_input.csv**.\n",
        "\n",
        "> Note: you will use this input data in both section 1 and section 2"
      ],
      "metadata": {
        "id": "jeEPi9tfWzx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = pd.read_csv('lab2_basic_input.csv')\n",
        "input_data"
      ],
      "metadata": {
        "id": "TIOE-YsHW3lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global attributes\n",
        "Define the global attributes\n",
        "> Note : You **cannot** modify the values of these attributes we have provided in the basic part"
      ],
      "metadata": {
        "id": "9cdYaIEjW7-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 2\n",
        "depth = 0\n",
        "min_samples_split = 2\n",
        "n_features = input_data.shape[1] - 1"
      ],
      "metadata": {
        "id": "S4WLhABvW6Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> You can add your own global attributes here"
      ],
      "metadata": {
        "id": "Zxs3U-K2W-ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6x_2G6hNXA1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Function Implementation and Testing"
      ],
      "metadata": {
        "id": "5qvPkvOpXBgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 & 2: Calculate the Entropy and Information Gain\n",
        "In these steps, you will implement functions to calculate entropy and information gain. These metrics are crucial for determining the best way to split the dataset at each node in the decision tree.\n",
        "\n",
        "If you need some help on Entropy and Information Gain, please refer to\n",
        "* https://codingnomads.com/decision-tree-information-gain-entropy#what-is-entropy\n",
        "* https://www.mldawn.com/decision-trees-entropy/#:~:text=In%20a%20binary%20classification%20problem%2C%20when%20Entropy%20hits%200%20it,state%20of%20purity%20and%20certainty.\n"
      ],
      "metadata": {
        "id": "1WWTmDqyXGR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(data):\n",
        "  \"\"\"\n",
        "  This function measures the amount of uncertainty in a probability distribution\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you're calculating for the entropy\n",
        "  return:\n",
        "  * entropy_value(type: float): the data's entropy\n",
        "  \"\"\"\n",
        "  p = 0 # to count the number of cases that survived\n",
        "  n = 0 # to count the number of cases that passed away\n",
        "\n",
        "  ### START CODE HERE ###\n",
        "  # Hint 1: what is the equation for calculating entropy?\n",
        "  # Hint 2: consider the case when p == 0 or n == 0, what should entropy be?\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return entropy_value\n",
        "\n",
        "# [Note] You have to save the value of \"ans_entropy\" into the output file\n",
        "# Please round your answer to 4 decimal place\n",
        "ans_entropy = entropy(input_data)\n",
        "print(\"ans_entropy = \", ans_entropy)"
      ],
      "metadata": {
        "id": "4j-LodsRXLd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> ans_entropy =  0.9928"
      ],
      "metadata": {
        "id": "k6pZ-HjJiDWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(data, mask):\n",
        "  \"\"\"\n",
        "  This function will calculate the information gain\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you're calculating for the information gain\n",
        "  * mask(type: Series): partition information(left/right) of current input data,\n",
        "    - boolean 1(True) represents split to left subtree\n",
        "    - boolean 0(False) represents split to right subtree\n",
        "  return:\n",
        "  * ig(type: float): the information gain you can obtain by classifying the data with this given mask\n",
        "  \"\"\"\n",
        "  ### START CODE HERE ###\n",
        "  # Hint: you should use mask to split the data into two, then recall what is the equation for calculating information gain\n",
        "  left = ...\n",
        "  right = ...\n",
        "\n",
        "  ig = ...\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return ig\n",
        "\n",
        "# [Note] You have to save the value of \"ans_informationGain\" into your output file\n",
        "# Here, let's assume that we split the input_data with 2/3 of the data in the left subtree and 1/3 in the right subtree\n",
        "# Please round your answer to 4 decimal place\n",
        "temp1 = np.zeros((int(input_data.shape[0]/3), 1), dtype=bool)\n",
        "temp2 = np.ones(((input_data.shape[0]-int(input_data.shape[0]/3), 1)), dtype=bool)\n",
        "temp_mask = np.concatenate((temp1, temp2))\n",
        "df_mask = pd.DataFrame(temp_mask, columns=['mask'])\n",
        "ans_informationGain = information_gain(input_data, df_mask['mask'])\n",
        "print(\"ans_informationGain = \", ans_informationGain)"
      ],
      "metadata": {
        "id": "hTvkGOCdXS0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> ans_informationGain = 0.0385"
      ],
      "metadata": {
        "id": "v5RLtCwcieQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Find the Best Split\n",
        "In this step, you will use the information gain calculated for each feature to find the best split. The best split is the point where the dataset is divided into two subgroups (left and right subtrees) in a way that maximizes the reduction of entropy.\n",
        "\n",
        "\n",
        "> Method: The process involves evaluating **every possible split** for each feature in the dataset. After sorting the data, you calculate potential split points by taking the **median of two consecutive values** where they differ. This median value becomes the threshold for splitting the data into two branches. The split that results in the highest information gain is selected as the best split.\n",
        "\n",
        "> Note: The method we have provided is a straightforward and basic approach. Please use this method to complete the basic part of the assignment. However, for the advanced part, you are welcome to explore and use other methods to fine-tune your model."
      ],
      "metadata": {
        "id": "rXajOk9jXefG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_split(data, impl_part):\n",
        "  \"\"\"\n",
        "  This function will find the best split combination of data\n",
        "  args:\n",
        "  * data(type: DataFrame): the input data\n",
        "  * impl_part(type: string): 'basic' or 'advanced' to specify which implementation to use\n",
        "  return\n",
        "  * best_ig(type: float): the best information gain you obtain\n",
        "  * best_threshold(type: float): the value that splits data into 2 branches\n",
        "  * best_feature(type: string): the feature that splits data into 2 branches\n",
        "  \"\"\"\n",
        "  best_ig = -1e9\n",
        "  best_threshold = 0\n",
        "  best_feature = ''\n",
        "\n",
        "  if(impl_part == 'basic'):\n",
        "    # Implement this part of the function using the method we provided\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "  else:\n",
        "    # You can implement another method here for the advanced part\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "\n",
        "  return best_ig, best_threshold, best_feature\n",
        "\n",
        "\n",
        "# [Note] You have to save the value of \"ans_ig\", \"ans_value\", and \"ans_name\" into the output file\n",
        "# Here, let's try to find the best split for the input_data\n",
        "# Please round your answer to 4 decimal place\n",
        "ans_ig, ans_value, ans_name = find_best_split(input_data, 'basic')\n",
        "print(\"ans_ig = \", ans_ig)\n",
        "print(\"ans_value = \", ans_value)\n",
        "print(\"ans_name = \", ans_name)"
      ],
      "metadata": {
        "id": "oT8UOEtzXiEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> ans_ig =  0.2146\n",
        "\n",
        "> ans_value =  99.5\n",
        "\n",
        "> ans_name =  glucose_apache"
      ],
      "metadata": {
        "id": "ovN6pxbXjQE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Split into 2 branches\n",
        "\n",
        "When you are building a decision tree, after identifying the best split, you will divide the dataset into two branches: a left branch and a right branch. Each branch represents a subset of the data based on the chosen **feature** and **split point**.\n",
        "\n",
        "* The left branch will contain the data points that meet the condition of the split (e.g., values less than or equal to the split threshold).\n",
        "* The right branch will contain the remaining data points (e.g., values greater than the split threshold).\n",
        "\n",
        "This step is essential because it creates the subgroups that the decision tree will continue to split in subsequent steps. By repeatedly splitting the data into smaller and more homogenous branches, the tree becomes more capable of accurately classifying new data points."
      ],
      "metadata": {
        "id": "n6koURsiXwjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_partition(data, feature, threshold):\n",
        "  \"\"\"\n",
        "  This function will split the data into 2 branches\n",
        "  args:\n",
        "  * data(type: DataFrame): the input data\n",
        "  * feature(type: string): the attribute(column name)\n",
        "  * threshold(type: float): the threshold for splitting the data\n",
        "  return:\n",
        "  * left(type: DataFrame): the divided data that matches(less than or equal to) the assigned feature's threshold\n",
        "  * right(type: DataFrame): the divided data that doesn't match the assigned feature's threshold\n",
        "  \"\"\"\n",
        "  ### START CODE HERE ###\n",
        "  left = ...\n",
        "  right = ...\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return left, right\n",
        "\n",
        "\n",
        "# [Note] You have to save the value of \"ans_left\" into the output file\n",
        "# Here, let's assume the best split is when we choose bmi as the feature and threshold as 21.0\n",
        "left, right = make_partition(input_data, 'bmi', 21.0)\n",
        "ans_left = left.shape[0]\n",
        "print(\"ans_left = \", ans_left)"
      ],
      "metadata": {
        "id": "0u0_dlPwX07H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> ans_left = 7"
      ],
      "metadata": {
        "id": "SJjyqmgXj2GX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Build the Decision Tree\n",
        "Hang in there... we are almost done with this section!\n",
        "\n",
        "Now, you need to use the above functions to complete a build_tree function.\n",
        "\n",
        "> Method:\n",
        "1.  If current depth < max_depth and the remaining number of samples > min_samples_split: continue to classify those samples\n",
        "2.  Use function *find_best_split()* to find the best split combination\n",
        "3.  If the obtained information gain is **greater than 0**: can build a deeper decision tree (add depth)\n",
        "4. Use function *make_partition()* to split the data into two parts\n",
        "5. Save the features and corresponding thresholds (starting from the root) used by the decision tree into *ans_features[]* and *ans_thresholds[]* respectively"
      ],
      "metadata": {
        "id": "sJKThK7yX8XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(data, max_depth, min_samples_split, depth):\n",
        "  \"\"\"\n",
        "  This function will build the decision tree\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you want to apply to the decision tree\n",
        "  * max_depth: the maximum depth of a decision tree\n",
        "  * min_samples_split: the minimum number of instances required to do partition\n",
        "  * depth: the height of the current decision tree\n",
        "  return:\n",
        "  * subtree: the decision tree structure including root, branch, and leaf (with the attributes and thresholds)\n",
        "  \"\"\"\n",
        "  ### START CODE HERE ###\n",
        "  # check the condition of current depth and the remaining number of samples\n",
        "  if ..... :\n",
        "    # call find_best_split() to find the best combination\n",
        "\n",
        "    # check the value of information gain is greater than 0 or not\n",
        "    if ..... :\n",
        "      # update the depth\n",
        "\n",
        "      # call make_partition() to split the data into two parts\n",
        "\n",
        "      # If there is no data split to the left tree OR no data split to the right tree\n",
        "      if ..... :\n",
        "        # return the label of the majority\n",
        "        label = .....\n",
        "        return label\n",
        "      else:\n",
        "        question = \"{} {} {}\".format(feature, \"<=\", threshold)\n",
        "        subtree = {question: []}\n",
        "\n",
        "        # call function build_tree() to recursively build the left subtree and right subtree\n",
        "\n",
        "        if left_subtree == right_subtree:\n",
        "          subtree = left_subtree\n",
        "        else:\n",
        "          subtree[question].append(left_subtree)\n",
        "          subtree[question].append(right_subtree)\n",
        "    else:\n",
        "      # return the label of the majority\n",
        "      label = .....\n",
        "      return label\n",
        "  else:\n",
        "    # return the label of the majority\n",
        "    label = .....\n",
        "    return label\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return subtree"
      ],
      "metadata": {
        "id": "ZC7qkOjAYAlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of the output from *build_tree()*\n",
        "```\n",
        "{'bmi <= 33.5': [1, {'age <= 68.5': [0, 1]}]}\n",
        "```\n",
        "Therefore,\n",
        "```\n",
        "ans_features = ['bmi', 'age']\n",
        "ans_thresholds = [33.5, 68.5]\n",
        "```"
      ],
      "metadata": {
        "id": "U7URY3IMkULl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, let's build a decision tree using the input_data\n",
        "\n",
        "ans_features = []\n",
        "ans_thresholds = []\n",
        "\n",
        "decisionTree = build_tree(input_data, max_depth, min_samples_split, depth)\n",
        "decisionTree"
      ],
      "metadata": {
        "id": "dAuaqjhuYQSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> decisionTree = {'glucose_apache <= 99.5': [{'height <= 184.15': [0, 1]}, 1]}"
      ],
      "metadata": {
        "id": "cD6A_jADyTjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Note] You have to save the features in the \"decisionTree\" structure (from root to branch and leaf) into the output file\n",
        "ans_features"
      ],
      "metadata": {
        "id": "oTdQ3vVkYYEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> ans_features = ['height', 'glucose_apache']"
      ],
      "metadata": {
        "id": "HZO17E9vkbi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Note] You have to save the corresponding thresholds for the features in the \"ans_features\" list into the output file\n",
        "ans_thresholds"
      ],
      "metadata": {
        "id": "BUeZh1o5YYem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> ans_thresholds = [184.15, 99.5]"
      ],
      "metadata": {
        "id": "tUPTy5RWj-1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Save answers"
      ],
      "metadata": {
        "id": "69TQQNVaYdmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic = []\n",
        "basic.append(ans_entropy)\n",
        "basic.append(ans_informationGain)\n",
        "basic.append([ans_ig, ans_value, ans_name])\n",
        "basic.append(ans_left)\n",
        "basic.append(ans_features + ans_thresholds)"
      ],
      "metadata": {
        "id": "B9DosXRQYbDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Build a Decision Tree Model\n",
        "\n",
        "Congrats! You have completed all 5 crucial functions. Now, we will use the functions above to implement a simple decision tree. You will train the decision tree using a training set and make predictions using a validation set."
      ],
      "metadata": {
        "id": "LpMpPwySYlUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Split data into training set and validation set\n",
        "> Note: We have split the data into training set and validation. You **cannot** change the distribution of the data."
      ],
      "metadata": {
        "id": "-1egGj-lYn6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = 30\n",
        "num_validation = 10\n",
        "\n",
        "training_data = input_data.iloc[:num_train]\n",
        "validation_data = input_data.iloc[-num_validation:]\n",
        "\n",
        "y_train = training_data[['hospital_death']]\n",
        "x_train = training_data.drop(['hospital_death'], axis=1)\n",
        "\n",
        "y_validation = validation_data[['hospital_death']]\n",
        "x_validation = validation_data.drop(['hospital_death'], axis=1)\n",
        "y_validation = y_validation.values.flatten()\n",
        "\n",
        "print(input_data.shape)\n",
        "print(training_data.shape)\n",
        "print(validation_data.shape)"
      ],
      "metadata": {
        "id": "GAHFMO4QYpZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 to 4 : Make predictions with a decision tree"
      ],
      "metadata": {
        "id": "pQlhfOJ0YySZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the attributions of the decision tree\n",
        "> You **cannot** modify the values of these attributes in this part"
      ],
      "metadata": {
        "id": "M5IHxhEjY1rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 2\n",
        "depth = 0\n",
        "min_samples_split = 2\n",
        "n_features = x_train.shape[1]"
      ],
      "metadata": {
        "id": "Vwt7BRJ1Y3hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have finished the function 'classify_data()' below, however, you can modify this function if you prefer completing it on your own way."
      ],
      "metadata": {
        "id": "6-ly7gvtY5VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_data(instance, tree):\n",
        "  \"\"\"\n",
        "  This function will predict/classify the input instance\n",
        "  args:\n",
        "  * instance: a instance(case) to be predicted\n",
        "  return:\n",
        "  * answer: the prediction result (the classification result)\n",
        "  \"\"\"\n",
        "  equation = list(tree.keys())[0]\n",
        "  if equation.split()[1] == '<=':\n",
        "    temp_feature = equation.split()[0]\n",
        "    temp_threshold = equation.split()[2]\n",
        "    if instance[temp_feature] > float(temp_threshold):\n",
        "      answer = tree[equation][1]\n",
        "    else:\n",
        "      answer = tree[equation][0]\n",
        "  else:\n",
        "    if instance[equation.split()[0]] in (equation.split()[2]):\n",
        "      answer = tree[equation][0]\n",
        "    else:\n",
        "      answer = tree[equation][1]\n",
        "\n",
        "  if not isinstance(answer, dict):\n",
        "    return answer\n",
        "  else:\n",
        "    return classify_data(instance, answer)\n",
        "\n",
        "\n",
        "def make_prediction(tree, data):\n",
        "  \"\"\"\n",
        "  This function will use your pre-trained decision tree to predict the labels of all instances in data\n",
        "  args:\n",
        "  * tree: the decision tree\n",
        "  * data: the data to predict\n",
        "  return:\n",
        "  * y_prediction: the predictions\n",
        "  \"\"\"\n",
        "  ### START CODE HERE ###\n",
        "  # [Note] You can call the function classify_data() to predict the label of each instance\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return y_prediction\n",
        "\n",
        "\n",
        "def calculate_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  This function will calculate the f1-score of the predictions\n",
        "  args:\n",
        "  * y_true: the ground truth\n",
        "  * y_pred: the predictions\n",
        "  return:\n",
        "  * score: the f1-score\n",
        "  \"\"\"\n",
        "  score = f1_score(y_true, y_pred)\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "V4LfxAnYY6UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree = build_tree(training_data, max_depth, min_samples_split, depth)\n",
        "\n",
        "y_pred = make_prediction(decision_tree, x_validation)\n",
        "\n",
        "# [Note] You have to save the value of \"ans_f1score\" into your output file\n",
        "# Please round your answer to 4 decimal place\n",
        "ans_f1score = calculate_score(y_validation, y_pred)\n",
        "ans_f1score = round(ans_f1score, 4)\n",
        "print(\"ans_f1score = \", ans_f1score)"
      ],
      "metadata": {
        "id": "_VEmtbmtZLQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> ans_f1score =  0.4444"
      ],
      "metadata": {
        "id": "lUcJZRYZk4kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is just for you to check your predictions\n",
        "y_pred"
      ],
      "metadata": {
        "id": "5t58_-BwpGnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output:\n",
        "> y_pred = [1, 1, 0, 1, 0, 0, 0, 0, 0, 1]"
      ],
      "metadata": {
        "id": "k7NM7CvdpHzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Save answer"
      ],
      "metadata": {
        "id": "COjs0B5jZQ8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic.append(ans_f1score)"
      ],
      "metadata": {
        "id": "Hijx-U2yZUAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write to Output File\n",
        "Save all of your answers into a csv file named **lab2_basic.csv**\n",
        "> Note: Please do not touch the code in this step, we have made sure this outputs the correct file format."
      ],
      "metadata": {
        "id": "r9lr2gbVZUwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_path = 'lab2_basic.csv'\n",
        "\n",
        "basic_df = pd.DataFrame({'Id': range(len(basic)), 'Ans': basic})\n",
        "basic_df.set_index('Id', inplace=True)\n",
        "basic_df"
      ],
      "metadata": {
        "id": "a5_ifgVZZZKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_df.to_csv(basic_path, header = True, index = True)"
      ],
      "metadata": {
        "id": "OTK0JT1965qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Part** (65%)\n",
        "\n",
        "In the advanced section of this lab, you will enhance your prediction capabilities by implementing a more powerful and complex machine learning model—Random Forests. Random Forests are an ensemble learning method that builds multiple decision trees and combines their outputs to improve prediction accuracy and model robustness.\n",
        "> * Step 1: Load training and testing data\n",
        "> * Step 2: Split training data into training and validation set\n",
        "> * Step 3: Build a Random Forest\n",
        "> * Step 4: Make predictions with the random forest\n",
        "> * Step 5: Write the Output File\n",
        "\n",
        "> ❗ **Important** ❗ You are allowed to create new functions to fine tune your random forest, but please make sure to **complete the functions provided**.\n",
        "\n",
        "\n",
        "\n",
        "We have attached some references if you need help:\n",
        "> https://medium.com/chung-yi/ml%E5%85%A5%E9%96%80-%E5%8D%81%E4%B8%83-%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-6afc24871857\n",
        "\n",
        "> https://www.geeksforgeeks.org/random-forest-algorithm-in-machine-learning/\n",
        "\n"
      ],
      "metadata": {
        "id": "Chm8Ro6zZsWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Load training and testing data\n",
        "First, load **lab2_advanced_training.csv**. You will use this to **train** the random forest."
      ],
      "metadata": {
        "id": "6kBs4D02Z0Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_training_data = pd.read_csv('lab2_advanced_training.csv')\n",
        "advanced_training_data"
      ],
      "metadata": {
        "id": "vLTMFK14Z4z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, load **lab2_advanced_testing.csv**. You will make predictions on this testing data using the pre-trained random forest model."
      ],
      "metadata": {
        "id": "HjPSZoAuZ4Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_testing_data = pd.read_csv('lab2_advanced_testing.csv')\n",
        "advanced_testing_data"
      ],
      "metadata": {
        "id": "6k-HFk7tZ_eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Split training data into training and validation set (Optional)\n",
        "> You can split the training data into training and validation set, this is up to you."
      ],
      "metadata": {
        "id": "OMQdTAvOaIh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### START CODE HERE ###\n",
        "training_data = ...\n",
        "validation_data = ...\n",
        "### END CODE HERE ###"
      ],
      "metadata": {
        "id": "iMan7jJ-aKX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Build a Random Forest\n",
        "\n",
        "Define the attributions of the random forest\n",
        "> * You **can** modify the values of these attributes in advanced part\n",
        "> * Each tree can have different attribute values\n",
        "> * Must use function *build_tree()* to build a random forest model\n",
        "> * Must print out the *selected_datas* and *selected_features*\n"
      ],
      "metadata": {
        "id": "xY8HvRY4af3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### START CODE HERE ###\n",
        "# Define the attributes\n",
        "max_depth = ...\n",
        "depth = ...\n",
        "min_samples_split = ...\n",
        "\n",
        "# total number of trees in a random forest\n",
        "n_trees = ...\n",
        "\n",
        "# number of features to train a decision tree\n",
        "n_features = ...\n",
        "\n",
        "# the ratio to select the number of instances\n",
        "sample_size = ...\n",
        "n_samples = int(training_data.shape[0] * sample_size)\n",
        "### END CODE HERE ###"
      ],
      "metadata": {
        "id": "xK0iM7goa2pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_forest(data, n_trees, n_features, n_samples):\n",
        "  \"\"\"\n",
        "  This function will build a random forest.\n",
        "  args:\n",
        "  * data: all data that can be used to train a random forest\n",
        "  * n_trees: total number of tree\n",
        "  * n_features: number of features\n",
        "  * n_samples: number of instances\n",
        "  return:\n",
        "  * forest: a random forest with 'n_trees' of decision tree\n",
        "  \"\"\"\n",
        "  ### START CODE HERE ###\n",
        "  data_len = ...\n",
        "  feature_list = ...\n",
        "  forest = []\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  # Create 'n_trees' number of trees and store each into the 'forest' list\n",
        "  for i in range(n_trees):\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Select 'n_samples' number of samples and 'n_features' number of features\n",
        "    # (you can select randomly or use any other techniques)\n",
        "\n",
        "    selected_datas = ...\n",
        "    selected_features = ...\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    print(f\"selected_datas = {selected_datas}\")\n",
        "    print(f\"selected_features = {selected_features}\")\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Store the rows in 'selected_datas' from 'data' into a new DataFrame\n",
        "    tree_data = pd.DataFrame()\n",
        "    ...\n",
        "\n",
        "    # Filter the DataFrame for specific 'selected_features' (columns)\n",
        "    tree_data = ...\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Then use the new data and 'build_tree' function to build a tree\n",
        "    tree = build_tree(tree_data, max_depth, min_samples_split, depth)\n",
        "    print(tree)\n",
        "\n",
        "    # Save your tree\n",
        "    forest.append(tree)\n",
        "\n",
        "  return forest"
      ],
      "metadata": {
        "id": "i1I7wbpWa_N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest = build_forest(training_data, n_trees, n_features, n_samples)"
      ],
      "metadata": {
        "id": "WvV8U7C2bIqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Make predictions with the random forest"
      ],
      "metadata": {
        "id": "CD0v4Af4bM_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction_forest(forest, data):\n",
        "  \"\"\"\n",
        "  This function will use the pre-trained random forest to make the predictions\n",
        "  args:\n",
        "  * forest: the random forest\n",
        "  * data: the data used to predict\n",
        "  return:\n",
        "  * y_prediction: the predicted results\n",
        "  \"\"\"\n",
        "  y_prediction = []\n",
        "  predictions = []\n",
        "\n",
        "  ### START CODE HERE ###\n",
        "  # Loop through each tree in the forest\n",
        "  for ...:\n",
        "    # Call 'make_prediction'\n",
        "    pred = ...\n",
        "    predictions.append(pred)\n",
        "\n",
        "  # Here, each tree has made its predictions.\n",
        "  # We can use majority vote in which the final prediction is determined by the mode (most frequent prediction) across all the trees.\n",
        "  # Feel free to use any other method to determine the final prediction\n",
        "\n",
        "  # Loop through each column of 'predictions'\n",
        "  for ...:\n",
        "    # For a specific column, find out each tree's prediction\n",
        "    column_predictions = ...\n",
        "    # Then, use a method to determine the final prediction for this column\n",
        "    # append the final prediction to y_prediction\n",
        "    if ...:\n",
        "      y_prediction.append(1)\n",
        "    else:\n",
        "      y_prediction.append(0)\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "\n",
        "\n",
        "  return y_prediction"
      ],
      "metadata": {
        "id": "45zA7JFVbRLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation (Optional)\n",
        "> If you split the data into training and validation sets in step 2, you can assess the accuracy of the forest here."
      ],
      "metadata": {
        "id": "zXED6E837NRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### START CODE HERE ###\n",
        "pred_validation = make_prediction_forest(forest, x_validation)\n",
        "score = calculate_score(y_validation, pred_validation)\n",
        "print(score)\n",
        "### END CODE HERE ###"
      ],
      "metadata": {
        "id": "CsC39J9P7h-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you have completed fine-tuning and validating the forest, you can proceed to make predictions on the test data."
      ],
      "metadata": {
        "id": "vqp8xzDJTV6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = make_prediction_forest(forest, advanced_testing_data)"
      ],
      "metadata": {
        "id": "atRpa9KoPgNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Write the Output File\n",
        "Save your predictions from the **random forest** in a csv file, named as **lab2_advanced.csv**\n",
        "> Note: Please do not touch the code in this step, we have made sure this outputs the correct file format."
      ],
      "metadata": {
        "id": "MfLRewfzbjiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced = []\n",
        "for i in range(len(y_pred_test)):\n",
        "  advanced.append(y_pred_test[i])"
      ],
      "metadata": {
        "id": "_H6MNjNmbst1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_path = 'lab2_advanced.csv'\n",
        "\n",
        "advanced_df = pd.DataFrame({'Id': range(len(advanced)), 'hospital_death': advanced})\n",
        "advanced_df.set_index('Id', inplace=True)\n",
        "advanced_df"
      ],
      "metadata": {
        "id": "7DHteTW7bvxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_df.to_csv(advanced_path, header = True, index = True)"
      ],
      "metadata": {
        "id": "AZWdWt5fGPe9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}